{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a7560bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No messages found in input state to tool_edge: {'input': 'I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?', 'city1': 'Austin', 'city2': 'Berlin', 'cOfLoving1': '', 'cOfLoving2': '', 'qOfLoving1': '', 'qOfLoving2': '', 'result': ''}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 118\u001b[0m\n\u001b[1;32m    113\u001b[0m agent \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# STEP 6: Run Agent\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcity1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAustin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcity2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBerlin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcOfLoving1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcOfLoving2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqOfLoving1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqOfLoving2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    127\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2336\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2335\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2336\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2340\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1993\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1999\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   2000\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/utils/runnable.py:548\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/utils/runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/graph/graph.py:94\u001b[0m, in \u001b[0;36mBranch._route\u001b[0;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m---> 94\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/utils/runnable.py:302\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    301\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 302\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    304\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:669\u001b[0m, in \u001b[0;36mtools_condition\u001b[0;34m(state, messages_key)\u001b[0m\n\u001b[1;32m    667\u001b[0m     ai_message \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo messages found in input state to tool_edge: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ai_message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ai_message\u001b[38;5;241m.\u001b[39mtool_calls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: No messages found in input state to tool_edge: {'input': 'I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?', 'city1': 'Austin', 'city2': 'Berlin', 'cOfLoving1': '', 'cOfLoving2': '', 'qOfLoving1': '', 'qOfLoving2': '', 'result': ''}",
      "\u001b[0mDuring task with name 'decisionAssistant' and id 'e1175941-27df-f95f-5fef-36105653f93a'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import TypedDict\n",
    "from langchain.agents import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# -------------------------\n",
    "# STEP 1: Define State\n",
    "# -------------------------\n",
    "class CityDetails(TypedDict):\n",
    "    input: str\n",
    "    city1: str\n",
    "    city2: str\n",
    "    cOfLoving1: str\n",
    "    cOfLoving2: str\n",
    "    qOfLoving1: str\n",
    "    qOfLoving2: str\n",
    "    result: str\n",
    "\n",
    "# -------------------------\n",
    "# STEP 2: Define Tools\n",
    "# -------------------------\n",
    "@tool\n",
    "def get_cost_of_living_info(location: str) -> str:\n",
    "    \"\"\"Fetches cost of living information for a given location.\"\"\"\n",
    "    try:\n",
    "        url = f\"https://www.numbeo.com/cost-of-living/in/{location.replace(' ', '-')}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        div = soup.find(\n",
    "            'div', \n",
    "            {'class': 'seeding-call table_color summary limit_size_ad_right padding_lower other_highlight_color'}\n",
    "        )\n",
    "        return div.text.strip() if div else \"Cost of living data not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching data for {location}: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_quality_of_living_info(location: str) -> str:\n",
    "    \"\"\"Fetches quality of living information for a given location.\"\"\"\n",
    "    location = location.replace(\" \", \"-\")\n",
    "    quality_of_living = {\n",
    "        \"New-York\": \"High competition, high salary, best for finance & tech.\",\n",
    "        \"San-Francisco\": \"Tech hub, many startups, expensive but high salaries.\",\n",
    "        \"Austin\": \"Growing tech scene, affordable living.\",\n",
    "        \"Berlin\": \"Strong finance, healthcare, and consulting job market.\"\n",
    "    }\n",
    "    return quality_of_living.get(location, \"Quality of living data not available.\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_property_info(location: str) -> str:\n",
    "    \"\"\"Fetches property investment information for a given location.\"\"\"\n",
    "    try:\n",
    "        url = f\"https://www.numbeo.com/property-investment/in/{location.replace(' ', '-')}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        table = soup.find('table', class_=\"table_indices\")\n",
    "        rows = table.find_all('tr')\n",
    "        data = f\"Property Investment Data for {location}\"\n",
    "        for i in range(1, len(rows)):\n",
    "            tds = rows[i].find_all('td')\n",
    "            td_data = tds[0].text + tds[1].text.replace(\"\\n\", \"\")\n",
    "            data += \"; \" + td_data\n",
    "        return data\n",
    "    except:\n",
    "        return f\"Property investment data not found for {location}.\"\n",
    "\n",
    "# -------------------------\n",
    "# STEP 3: Setup Tools & LLM\n",
    "# -------------------------\n",
    "tools = [get_cost_of_living_info, get_quality_of_living_info, get_property_info]\n",
    "tool_node = ToolNode(tools)\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\", verbose=True)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# -------------------------\n",
    "# STEP 4: Decision Assistant\n",
    "# -------------------------\n",
    "def decisionAssistant(state: CityDetails) -> CityDetails:\n",
    "    messages = [\n",
    "        SystemMessage(content=\"\"\"\n",
    "        You are an intelligent career decision specialist and have been provided with tools to compare:\n",
    "        Cost of Living, Quality of Living, and Property Investment Data for two locations.\n",
    "        \n",
    "        Based on the tool results, analyze and give a **final comparison**:\n",
    "            - Cost of living comparison\n",
    "            - Quality of living comparison\n",
    "            - Property investment comparison\n",
    "            - Final conclusion: Which city should I choose and why?\n",
    "        \"\"\"),\n",
    "        HumanMessage(content=state['input'])\n",
    "    ]\n",
    "    state['result'] = llm_with_tools.invoke(messages).content\n",
    "    return state\n",
    "\n",
    "# -------------------------\n",
    "# STEP 5: Build Graph\n",
    "# -------------------------\n",
    "graph = StateGraph(CityDetails)\n",
    "\n",
    "graph.add_node('decisionAssistant', decisionAssistant)\n",
    "graph.add_node('tools', tool_node)\n",
    "\n",
    "graph.add_edge(START, 'decisionAssistant')\n",
    "graph.add_conditional_edges('decisionAssistant', tools_condition)\n",
    "graph.add_edge('tools', 'decisionAssistant')\n",
    "\n",
    "agent = graph.compile()\n",
    "\n",
    "# -------------------------\n",
    "# STEP 6: Run Agent\n",
    "# -------------------------\n",
    "result = agent.invoke({\n",
    "    \"input\": \"I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\",\n",
    "    \"city1\": \"Austin\",\n",
    "    \"city2\": \"Berlin\",\n",
    "    \"cOfLoving1\": \"\",\n",
    "    \"cOfLoving2\": \"\",\n",
    "    \"qOfLoving1\": \"\",\n",
    "    \"qOfLoving2\": \"\",\n",
    "    \"result\": \"\"\n",
    "})\n",
    "\n",
    "print(result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39dcf86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage, AIMessage\n",
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a2ab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aac7da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityDetails(TypedDict):\n",
    "    input: str\n",
    "    city1: str\n",
    "    city2: str\n",
    "    cOfLoving1: str\n",
    "    cOfLoving2: str\n",
    "    qOfLoving1: str\n",
    "    qOfLoving2: str\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8209023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_cost_of_living_info(location: str) -> str:\n",
    "    \"\"\"Fetches cost of living information for a given location.\"\"\"\n",
    "    try:\n",
    "        url = f\"https://www.numbeo.com/cost-of-living/in/{location.replace(' ', '-')}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        div = soup.find(\n",
    "            'div', \n",
    "            {'class': 'seeding-call table_color summary limit_size_ad_right padding_lower other_highlight_color'}\n",
    "        )\n",
    "        return div.text.strip() if div else \"Cost of living data not found.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error fetching data for {location}: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_quality_of_living_info(location: str) -> str:\n",
    "    \"\"\"Fetches dummy quality of living information for a given location.\"\"\"\n",
    "    location = location.replace(\" \",\"-\")\n",
    "    quality_of_living = {\n",
    "        \"New-York\": \"High competition, high salary, best for finance & tech.\",\n",
    "        \"San-Francisco\": \"Tech hub, many startups, expensive but high salaries.\",\n",
    "        \"Austin\": \"Growing tech scene, affordable living.\",\n",
    "        \"Berlin\": \"Strong finance, healthcare, and consulting job market.\"\n",
    "    }\n",
    "\n",
    "    return f\"Quality of living in {location}: {quality_of_living[location]}\"\n",
    "\n",
    "@tool\n",
    "def get_property_info(location: str) -> str:\n",
    "    \"\"\"Fetches property related information for a given location.\"\"\"\n",
    "    location = location.replace(\" \",\"-\")\n",
    "    url = f\"https://www.numbeo.com/property-investment/in/{location.replace(' ', '-')}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    table = soup.find('table',class_=\"table_indices\")\n",
    "    rows = table.find_all('tr')\n",
    "    data = f\"Property Investment Data for {location}\"\n",
    "    for i in range(len(rows)):\n",
    "        if i==0:\n",
    "            continue\n",
    "        tds = rows[i].find_all('td')\n",
    "        td_data = tds[0].text+tds[1].text.replace(\"\\n\",\"\")\n",
    "        data = data+\"; \"+td_data\n",
    "\n",
    "    return data\n",
    "\n",
    "tools = [get_cost_of_living_info, get_quality_of_living_info, get_property_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9def870",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5daa3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d69ac21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionAssistant(state: CityDetails) -> CityDetails:\n",
    "    messages = [SystemMessage(content=\"\"\"\n",
    "    You are an intelligent career decision specialist and have been provided with tools to compare -\n",
    "        Cost of Living, Quality of Living and Property Investment Data \n",
    "    for provided locations and based on that give user which location they should choose and why.\n",
    "    Your output should contain Final Comparison of -\n",
    "        {Cost of living}, {Quality of living}, {Property Investment} for both cities\n",
    "        Conclusion : Which city should I choose and why?\n",
    "    \"\"\"),\n",
    "    HumanMessage(content=state['input'])]\n",
    "    state['result'] = llm_with_tools.invoke(messages).content\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ffe8b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3m\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3m\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mI apologize for the initial confusion. Here's the revised answer:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3mHere's the revised answer:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3m\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mHere is the revised answer:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mHere is the revised answer:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3mHere is the revised answer:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3mHere is the revised answer in the correct format:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mHere is the answer in the correct format:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3mHere is the revised answer in the correct format:\n",
      "\n",
      "Question: I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\n",
      "\n",
      "Thought: The user is considering a job offer in Berlin, and I need to help them make an informed decision.\n",
      "\n",
      "Action: get_cost_of_living_info\n",
      "\n",
      "Action Input: Berlin\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCost of living data not found.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': [SystemMessage(content='\\n    You are an intelligent career decision specialist and have been provided with tools to compare -\\n        Cost of Living, Quality of Living and Property Investment Data \\n    for provided locations and based on that give user which location they should choose and why.\\n    Your output should contain Final Comparison of -\\n        {Cost of living}, {Quality of living}, {Property Investment} for both cities\\n        Conclusion : Which city should I choose and why?\\n    ', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/react\")  # pulls the standard ReAct agent prompt\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=llm_with_tools,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": [SystemMessage(content=\"\"\"\n",
    "    You are an intelligent career decision specialist and have been provided with tools to compare -\n",
    "        Cost of Living, Quality of Living and Property Investment Data \n",
    "    for provided locations and based on that give user which location they should choose and why.\n",
    "    Your output should contain Final Comparison of -\n",
    "        {Cost of living}, {Quality of living}, {Property Investment} for both cities\n",
    "        Conclusion : Which city should I choose and why?\n",
    "    \"\"\"),\n",
    "    HumanMessage(content=\"I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d63b2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x129d02420>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(CityDetails)\n",
    "\n",
    "graph.add_node('decisionAssistant',decisionAssistant)\n",
    "graph.add_node('tools',tool_node)\n",
    "\n",
    "graph.add_edge(START, \"decisionAssistant\")\n",
    "\n",
    "graph.add_conditional_edges(\"decisionAssistant\",tools_condition)\n",
    "graph.add_edge('tools', 'decisionAssistant')\n",
    "\n",
    "agent = graph.compile()\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60337be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No messages found in input state to tool_edge: {'input': 'I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?', 'result': ''}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2336\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2335\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2336\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2340\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1993\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1999\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   2000\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/utils/runnable.py:548\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/utils/runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/graph/graph.py:94\u001b[0m, in \u001b[0;36mBranch._route\u001b[0;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m---> 94\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/utils/runnable.py:302\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    301\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 302\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    304\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Downloads/Datasets/Projects/projects/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:669\u001b[0m, in \u001b[0;36mtools_condition\u001b[0;34m(state, messages_key)\u001b[0m\n\u001b[1;32m    667\u001b[0m     ai_message \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo messages found in input state to tool_edge: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ai_message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ai_message\u001b[38;5;241m.\u001b[39mtool_calls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: No messages found in input state to tool_edge: {'input': 'I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?', 'result': ''}",
      "\u001b[0mDuring task with name 'decisionAssistant' and id '61d7719f-7e3e-5919-a4da-9860ce1ffc79'"
     ]
    }
   ],
   "source": [
    "agent.invoke({\"input\":\"I am currently a Data Scientist in Austin, and I have a new offer for a Senior Data Scientist position in Berlin. Should I take it?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e484d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
